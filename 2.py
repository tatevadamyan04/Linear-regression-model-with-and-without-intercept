import numpy as np

# Данные
X = np.array([35, 45, 190, 200, 40, 70, 54, 150, 120, 110])
y = np.array([401, 574, 874, 919, 459, 739, 653, 902, 746, 832])

# Гиперпараметры
learning_rate = 0.0001  # Коэффициент обучения
num_iterations = 10000  # Количество итераций

# Инициализация коэффициента
beta1 = 0

# Градиентный спуск
n = len(X)
for _ in range(num_iterations):
    # Вычисление градиента
    gradient = -2 / n * np.sum(X * (y - beta1 * X))
    
    # Обновление коэффициента
    beta1 -= learning_rate * gradient

# Вывод результата
print(f"Коэффициент линейной регрессии без интерсепта, вычисленный методом градиентного спуска: {beta1:.2f}")
